{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lhg45\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\", context=\"talk\")\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "from torch.utils.data import dataloader, dataset\n",
    "\n",
    "import transformers\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.metrics import f1_score, mean_squared_error, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./dataset/train.csv.zip')\n",
    "test = pd.read_csv('./dataset/test.csv.zip')\n",
    "test_label = pd.read_csv('./dataset/test_labels.csv.zip')\n",
    "new_test = pd.merge(test, test_label, on='id', how='inner')\n",
    "new_test = new_test[(new_test.iloc[:, 3:8] != -1).all(axis=1)]\n",
    "train.head()\n",
    "#new_test = new_test.head(1000)\n",
    "#test.head()\n",
    "#test_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the dataset -- helper function for removing non-sense fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    #pattern = [zero or more character]\n",
    "\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    #pattern = removes (http),://, 'and' www.\n",
    "    \n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    #pattern = any punctionation\n",
    "\n",
    "    text = re.sub('\\n', '', text)\n",
    "    #pattern = any new line\n",
    "\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    #pattern = any from[a-zA-Z0-9_], any from[0-9], any from [a-zA-Z0-9_]\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "train['clean'] = train['comment_text'].apply(str).apply(lambda x: clean_text(x))\n",
    "new_test['clean'] = new_test['comment_text'].apply(str).apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataSet(dataset.Dataset):\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_len, if_train=True):\n",
    "        self.texts = texts\n",
    "        #self.labels = labels.to_numpy()\n",
    "        self.if_train = if_train\n",
    "        if self.if_train:\n",
    "            self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts.iloc[item])\n",
    "        \n",
    "        if self.if_train:\n",
    "            label = self.labels.iloc[item]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        if self.if_train:\n",
    "            return {\n",
    "                #'text': text,\n",
    "                'input_ids':torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "                'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "                'labels': torch.tensor(label, dtype=torch.float)\n",
    "            }\n",
    "        else:\n",
    "            return{\n",
    "            'input_ids':torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long)\n",
    "            }\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The devices using is : cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_batch = 32\n",
    "valid_batch = 32\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "print(f\"The devices using is : {device}\")\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 6).to(device)\n",
    "\n",
    "fold_losses = []\n",
    "fold_valid = []\n",
    "\n",
    "best_model  = None\n",
    "best_loss = None\n",
    "best_index = 0\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss() # for sigmoid on multi-label tasks\n",
    "loss_fn.to(device)\n",
    "\n",
    "LR  = 2e-7\n",
    "\n",
    "optimizer = AdamW(model.parameters(), LR, betas = (0.9, 0.999), weight_decay = 1e-2)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "train_steps = int((len(train) * epochs)/train_batch)\n",
    "num_steps = int(train_steps * 0.1)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze Layers\n",
    "for param in model.bert.embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for layer in model.bert.encoder.layer[:3]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkf = KFold(n_splits = 5, shuffle = True, random_state=42)\\n\\ntrain_index, valid_index = next(iter(kf.split(train)))\\n\\ntrain_kf = train.iloc[train_index].reset_index(drop = True)\\nvalid_kf = train.iloc[valid_index].reset_index(drop = True)\\n\\ntrain_dataset = BertDataSet(train_kf[\\'clean\\'], train_kf[[\\'toxic\\', \\'severe_toxic\\',\\'obscene\\', \\'threat\\', \\'insult\\',\\'identity_hate\\']], tokenizer, 128)\\nvalid_dataset = BertDataSet(valid_kf[\\'clean\\'], valid_kf[[\\'toxic\\', \\'severe_toxic\\',\\'obscene\\', \\'threat\\', \\'insult\\',\\'identity_hate\\']], tokenizer, 128)\\n\\n#train_dataset = BertDataSet(train_kf, tokenizer, eval_mode = False)\\n#valid_dataset = BertDataSet(valid_kf, tokenizer, eval_mode = True)\\n\\ntrain_dataloader = dataloader.DataLoader(train_dataset, batch_size = train_batch, pin_memory = True, num_workers = 0, shuffle = True)\\nvalid_dataloader = dataloader.DataLoader(valid_dataset, batch_size = valid_batch, pin_memory = True, num_workers = 0, shuffle = False)\\n\\n\\ntraining_losses = []\\nvalid_losses = []\\n\\ntotal_steps = len(train_dataloader) * epochs\\n\\n#scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)\\n\\n\\nfor epoch in range(epochs):   \\n    model.train()\\n    train_losses = []\\n    valid_losses = []\\n    with torch.cuda.amp.autocast():\\n    \\n        for batch in tqdm(train_dataloader):\\n            \\n            optimizer.zero_grad()\\n            input_ids = batch[\\'input_ids\\'].to(device)\\n            attention_mask = batch[\\'mask\\'].to(device)\\n            labels = batch[\\'labels\\'].to(device)\\n            \\n            outputs = model(input_ids, attention_mask=attention_mask, labels = labels)\\n            outputs = outputs[\\'logits\\']\\n            \\n            toxic_labels = batch[\\'labels\\'].to(device, non_blocking=True)\\n            loss = loss_fn(outputs, toxic_labels)\\n            \\n            #loss = outputs.loss\\n            train_losses.append(loss.item())\\n            \\n            loss.backward()\\n            optimizer.step()\\n            \\n            scheduler.step()\\n            \\n        avg_loss = np.mean(train_losses)\\n        training_losses.append(avg_loss)\\n        print(f\"Training Epoch {epoch+1}/{epochs}, Loss: {avg_loss}.\")\\n    \\n        model.eval()\\n        true_labels = []\\n        predictions = []\\n        \\n        for batch in valid_dataloader:\\n            \\n            input_ids = batch[\\'input_ids\\'].to(device)\\n            attention_mask = batch[\\'mask\\'].to(device)\\n            labels = batch[\\'labels\\'].to(device)\\n                    \\n            \\n            with torch.no_grad():\\n                #outputs = model(input_ids, attention_mask = attention_mask)\\n                outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\\n                \\n            outputs = outputs[\\'logits\\'].squeeze(-1)\\n            \\n            toxic_labels = batch[\\'labels\\'].to(device, non_blocking=True)\\n            loss = loss_fn(outputs, toxic_labels)\\n            #loss = outputs.loss\\n            valid_losses.append(loss.item())\\n            \\n        avg_valid_loss = np.mean(valid_losses)\\n        valid_losses.append(avg_valid_loss)   \\n        #f1 = f1_score(true_labels, predictions, average=\\'weighted\\')  #Error : Classification metrics can\\'t handle a mix of multilabel-indicator and binary targets       \\n        print(f\"Validating Epoch {epoch+1}/{epochs}, Loss: {avg_valid_loss}\")\\n    \\nbest_model = model\\nbest_loss = avg_valid_loss\\nfold_losses = training_losses\\nfold_valid = valid_losses\\nbest_model.save_pretrained(\\'./fintune_bert\\')    \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state=42)\n",
    "\n",
    "train_index, valid_index = next(iter(kf.split(train)))\n",
    "\n",
    "train_kf = train.iloc[train_index].reset_index(drop = True)\n",
    "valid_kf = train.iloc[valid_index].reset_index(drop = True)\n",
    "\n",
    "train_dataset = BertDataSet(train_kf['clean'], train_kf[['toxic', 'severe_toxic','obscene', 'threat', 'insult','identity_hate']], tokenizer, 128)\n",
    "valid_dataset = BertDataSet(valid_kf['clean'], valid_kf[['toxic', 'severe_toxic','obscene', 'threat', 'insult','identity_hate']], tokenizer, 128)\n",
    "\n",
    "#train_dataset = BertDataSet(train_kf, tokenizer, eval_mode = False)\n",
    "#valid_dataset = BertDataSet(valid_kf, tokenizer, eval_mode = True)\n",
    "\n",
    "train_dataloader = dataloader.DataLoader(train_dataset, batch_size = train_batch, pin_memory = True, num_workers = 0, shuffle = True)\n",
    "valid_dataloader = dataloader.DataLoader(valid_dataset, batch_size = valid_batch, pin_memory = True, num_workers = 0, shuffle = False)\n",
    "\n",
    "\n",
    "training_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "#scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):   \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    with torch.cuda.amp.autocast():\n",
    "    \n",
    "        for batch in tqdm(train_dataloader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels = labels)\n",
    "            outputs = outputs['logits']\n",
    "            \n",
    "            toxic_labels = batch['labels'].to(device, non_blocking=True)\n",
    "            loss = loss_fn(outputs, toxic_labels)\n",
    "            \n",
    "            #loss = outputs.loss\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "        avg_loss = np.mean(train_losses)\n",
    "        training_losses.append(avg_loss)\n",
    "        print(f\"Training Epoch {epoch+1}/{epochs}, Loss: {avg_loss}.\")\n",
    "    \n",
    "        model.eval()\n",
    "        true_labels = []\n",
    "        predictions = []\n",
    "        \n",
    "        for batch in valid_dataloader:\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "                    \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                #outputs = model(input_ids, attention_mask = attention_mask)\n",
    "                outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
    "                \n",
    "            outputs = outputs['logits'].squeeze(-1)\n",
    "            \n",
    "            toxic_labels = batch['labels'].to(device, non_blocking=True)\n",
    "            loss = loss_fn(outputs, toxic_labels)\n",
    "            #loss = outputs.loss\n",
    "            valid_losses.append(loss.item())\n",
    "            \n",
    "        avg_valid_loss = np.mean(valid_losses)\n",
    "        valid_losses.append(avg_valid_loss)   \n",
    "        #f1 = f1_score(true_labels, predictions, average='weighted')  #Error : Classification metrics can't handle a mix of multilabel-indicator and binary targets       \n",
    "        print(f\"Validating Epoch {epoch+1}/{epochs}, Loss: {avg_valid_loss}\")\n",
    "    \n",
    "best_model = model\n",
    "best_loss = avg_valid_loss\n",
    "fold_losses = training_losses\n",
    "fold_valid = valid_losses\n",
    "best_model.save_pretrained('./fintune_bert')    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# draw the losses of the best model\\nbest_train_losses = fold_losses\\nbest_valid_losses = valid_losses\\n\\nplt.plot(best_train_losses, color='green')\\nplt.plot(best_valid_losses, color = 'blue')\\nplt.xlabel('Epoch')\\nplt.ylabel('Average Loss')\\nplt.title('Loss Plot')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# draw the losses of the best model\n",
    "best_train_losses = fold_losses\n",
    "best_valid_losses = valid_losses\n",
    "\n",
    "plt.plot(best_train_losses, color='green')\n",
    "plt.plot(best_valid_losses, color = 'blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Using K-folder\n",
    "kfold = 5\n",
    "train['kfold'] = train.index % kfold\n",
    "train.index % kfold\n",
    "\n",
    "p_train = train[train[\"kfold\"] != 0].reset_index(drop = True)\n",
    "p_valid = train[train[\"kfold\"] == 0].reset_index(drop = True)\n",
    "\n",
    "#Setting dataset\n",
    "train_dataset = BertDataSet(p_train['clean'], p_train[['toxic', 'severe_toxic','obscene', 'threat', 'insult','identity_hate']], tokenizer, 128)\n",
    "valid_dataset = BertDataSet(p_valid['clean'], p_valid[['toxic', 'severe_toxic','obscene', 'threat', 'insult','identity_hate']], tokenizer, 128)\n",
    "\n",
    "train_dataloader = dataloader.DataLoader(train_dataset, batch_size = train_batch, pin_memory = True, num_workers = 0, shuffle = True)\n",
    "valid_dataloader = dataloader.DataLoader(valid_dataset, batch_size = valid_batch, pin_memory = True, num_workers = 0, shuffle = False)\n",
    "\n",
    "\n",
    "def training(train_dataloader, model, optimizer, scheduler):\n",
    "    model.train()\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for batch in tqdm(train_dataloader):\n",
    "        losses = []\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            \n",
    "            ids = batch['input_ids'].to(device, non_blocking = True)\n",
    "            mask = batch['mask'].to(device, non_blocking = True) \n",
    "\n",
    "            output = model(ids, mask) \n",
    "            output = output['logits'].squeeze(-1).to(torch.float32)\n",
    "\n",
    "            output_probs = torch.sigmoid(output)\n",
    "            \n",
    "            toxic_label = batch['labels'].to(device, non_blocking = True) \n",
    "            loss = loss_fn(output, toxic_label)            \n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            preds = torch.where(output_probs > 0.5, 1, 0)\n",
    "        \n",
    "            correct_predictions += torch.sum(preds == toxic_label)\n",
    "        \n",
    "        scaler.scale(loss).backward() \n",
    "        scaler.step(optimizer) \n",
    "        scaler.update() \n",
    "                        \n",
    "        scheduler.step() \n",
    "    \n",
    "    losses = np.mean(losses)\n",
    "    correctness = correct_predictions.detach().cpu().numpy()\n",
    "    accuracy = correctness/(len(p_train)*6)\n",
    "    \n",
    "    return losses, accuracy\n",
    "\n",
    "def validating(valid_dataloader, model):\n",
    "    \n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    all_output_probs = []\n",
    "    \n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        losses = []\n",
    "        ids = batch['input_ids'].to(device, non_blocking = True)\n",
    "        mask = batch['mask'].to(device, non_blocking = True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(ids, mask)\n",
    "            \n",
    "        output = output['logits'].squeeze(-1).to(torch.float32)\n",
    "        output_probs = torch.sigmoid(output)\n",
    "        preds = torch.where(output_probs > 0.5, 1, 0)\n",
    "            \n",
    "        toxic_label = batch['labels'].to(device, non_blocking = True)\n",
    "        loss = loss_fn(output, toxic_label)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        all_output_probs.extend(output_probs.detach().cpu().numpy())\n",
    "        \n",
    "        correct_predictions += torch.sum(preds == toxic_label)\n",
    "    \n",
    "    losses = np.mean(losses)\n",
    "    correctness = correct_predictions.detach().cpu().numpy()\n",
    "    accuracy = correctness/(len(p_valid)*6)\n",
    "    \n",
    "    return losses, accuracy, all_output_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for eboch in range(epochs):\n",
    "    \n",
    "    train_loss, train_acc = training(train_dataloader, model, optimizer, scheduler)\n",
    "    valid_loss, valid_acc, valid_probs = validating(valid_dataloader, model)\n",
    "    \n",
    "    print('train losses: %.4f' % train_loss, 'train accuracy: %.4f' % train_acc)\n",
    "    print('valid losses: %.4f' % valid_loss, 'valid accuracy: %.4f' % valid_acc)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_accs.append(valid_acc)\n",
    "    \n",
    "model.save_pretrained('./fintune_bert')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nx = np.arange(epochs)\\nfig, ax = plt.subplots(1, 2, figsize = (15,4))\\nax[0].plot(x, train_losses)\\nax[0].plot(x, valid_losses)\\nax[0].set_ylabel('Losses', weight = 'bold')\\nax[0].set_xlabel('Epochs')\\nax[0].grid(alpha = 0.3)\\nax[0].legend(labels = ['train losses', 'valid losses'])\\n\\nax[1].plot(x, train_accs)\\nax[1].plot(x, valid_accs)\\nax[1].set_ylabel('Accuracy', weight = 'bold')\\nax[1].set_xlabel('Epochs')\\nax[1].legend(labels = ['train acc', 'valid acc'])\\n\\nax[1].grid(alpha = 0.3)\\nfig.suptitle('Fold = 0', weight = 'bold') \\n\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = np.arange(epochs)\n",
    "fig, ax = plt.subplots(1, 2, figsize = (15,4))\n",
    "ax[0].plot(x, train_losses)\n",
    "ax[0].plot(x, valid_losses)\n",
    "ax[0].set_ylabel('Losses', weight = 'bold')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].grid(alpha = 0.3)\n",
    "ax[0].legend(labels = ['train losses', 'valid losses'])\n",
    "\n",
    "ax[1].plot(x, train_accs)\n",
    "ax[1].plot(x, valid_accs)\n",
    "ax[1].set_ylabel('Accuracy', weight = 'bold')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].legend(labels = ['train accuracy', 'valid accuracy'])\n",
    "\n",
    "ax[1].grid(alpha = 0.3)\n",
    "fig.suptitle('Fold = 0', weight = 'bold') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nconfig_path = \\'./fintune_bert/config.json\\'\\nmodel_path = \\'./fintune_bert/model.safetensors\\'\\nconfig = transformers.BertConfig.from_json_file(config_path)\\nmodel = transformers.BertForSequenceClassification.from_pretrained(model_path, config=config).to(device) \\nvalid_loss, valid_acc, valid_probs = validating(valid_dataloader, model)\\nvalid_probs = np.asarray(valid_probs).flatten()\\ny_valid = p_valid[[\\'toxic\\', \\'severe_toxic\\',\\'obscene\\', \\'threat\\', \\'insult\\',\\'identity_hate\\']].to_numpy().flatten()\\nfpr, tpr, _ = roc_curve(y_valid, valid_probs)\\n\\nprint(\"Valid AUC_score : \" + str(roc_auc_score(y_valid, valid_probs)))\\n\\nfig, ax = plt.subplots()\\nax.plot(fpr, tpr)\\nax.set_title(\\'ROC Curv\\')\\nax.set_xlabel(\\'FPR\\')\\nax.set_ylabel(\\'TPR\\')\\nplt.show()\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "config_path = './fintune_bert/config.json'\n",
    "model_path = './fintune_bert/model.safetensors'\n",
    "config = transformers.BertConfig.from_json_file(config_path)\n",
    "model = transformers.BertForSequenceClassification.from_pretrained(model_path, config=config).to(device) \n",
    "valid_loss, valid_acc, valid_probs = validating(valid_dataloader, model)\n",
    "valid_probs = np.asarray(valid_probs).flatten()\n",
    "y_valid = p_valid[['toxic', 'severe_toxic','obscene', 'threat', 'insult','identity_hate']].to_numpy().flatten()\n",
    "fpr, tpr, _ = roc_curve(y_valid, valid_probs)\n",
    "\n",
    "print(\"Valid AUC_score : \" + str(roc_auc_score(y_valid, valid_probs)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr)\n",
    "ax.set_title('ROC Curv')\n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gc\n",
    "#tokenizer = None\n",
    "#best_model = None\n",
    "#model = None\n",
    "#torch.cuda.empty_cache()\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilabel ROC_AUC\n",
    "def get_roc_auc(test_label, y_prob):\n",
    "    # input: test_labels dim: (num_samples, num_labels), y_prob dim: (num_samples, num_labels)\n",
    "    y_label_np = test_label.numpy() if hasattr(test_label, 'numpy') else test_label.cpu().numpy()\n",
    "    y_test_np = y_prob.numpy() if hasattr(y_prob, 'numpy') else y_prob.cpu().numpy()\n",
    "\n",
    "    n_classes = y_label_np.shape[1]  # Number of classes/labels\n",
    "\n",
    "# Initialize lists to store fpr and tpr for each label\n",
    "    all_fpr = []\n",
    "    all_tpr = []\n",
    "    label_names = []\n",
    "    auc_scores = []\n",
    "    # Compute ROC curve for each label\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_label_np[:, i], y_test_np[:, i])\n",
    "        all_fpr.append(fpr)\n",
    "        all_tpr.append(tpr)\n",
    "        auc = roc_auc_score(y_label_np[:, i], y_test_np[:, i])\n",
    "        label_names.append(f\"Label {i}\")\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    # Plot ROC curve for each label\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(all_fpr[i], all_tpr[i], label=f'ROC curve (Label {i})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for each label')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    auc_table = pd.DataFrame({'Label': label_names, 'AUC Score': auc_scores})\n",
    "\n",
    "    print(auc_table)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_label, y_test):\n",
    "    prediction = torch.where(y_test > 0.5, 1, 0)\n",
    "    y_label_np = prediction.numpy() if hasattr(prediction, 'numpy') else prediction.cpu().numpy()\n",
    "    y_test_np = y_label.numpy() if hasattr(y_label, 'numpy') else y_label.cpu().numpy()\n",
    "    \n",
    "    n_class = y_label_np.shape[1]\n",
    "    n_samples = y_label_np.shape[0]\n",
    "\n",
    "    total_num = y_label_np.shape[0] * y_label_np.shape[1]\n",
    "    correct = 0\n",
    "    for i in range(n_class):\n",
    "        for j in range(n_samples):\n",
    "            if y_test_np[j,i] == y_label_np[j,i]:\n",
    "                correct += 1 \n",
    "    accuracy = correct / total_num\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_accuracy(y_label, y_test):\n",
    "    prediction = torch.where(y_test > 0.5, 1, 0)\n",
    "    y_label_np = prediction.numpy() if hasattr(prediction, 'numpy') else prediction.cpu().numpy()\n",
    "    y_test_np = y_label.numpy() if hasattr(y_label, 'numpy') else y_label.cpu().numpy()\n",
    "    \n",
    "    n_class = y_label_np.shape[1]\n",
    "    n_samples = y_label_np.shape[0]\n",
    "\n",
    "    total_num = y_label_np.shape[0] * y_label_np.shape[1]\n",
    "    false = 0\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_class):\n",
    "            if y_test_np[i,j] != y_label_np[i,j]:\n",
    "                false += 1\n",
    "                continue \n",
    "    accuracy = 1- false / n_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_F1(y_label, y_test):\n",
    "    prediction = torch.where(y_test > 0.5, 1, 0)\n",
    "    y_label_np = prediction.numpy() if hasattr(prediction, 'numpy') else prediction.cpu().numpy()\n",
    "    y_test_np = y_label.numpy() if hasattr(y_label, 'numpy') else y_label.cpu().numpy()\n",
    "    \n",
    "    n_class = y_label_np.shape[1]\n",
    "    n_samples = y_label_np.shape[0]\n",
    "\n",
    "    f1_scores = []\n",
    "    for i in range(n_class):\n",
    "        true_positives = 0\n",
    "        false_positives = 0\n",
    "        false_negatives = 0\n",
    "        for j in range(n_samples):\n",
    "            if y_test_np[j,i] == 1 and y_label_np[j,i] == 1:\n",
    "                true_positives += 1\n",
    "            elif y_test_np[j,i] == 1 and y_label_np[j,i] == 0:\n",
    "                false_positives += 1\n",
    "            elif y_test_np[j,i] == 0 and y_label_np[j,i] == 1:\n",
    "                false_negatives += 1\n",
    "\n",
    "        precision = true_positives / max(1, true_positives + false_positives)\n",
    "        recall = true_positives / max(1, true_positives + false_negatives)\n",
    "        \n",
    "        f1 = 2 * (precision * recall) / max(1e-6, precision + recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading test_dataset\n",
    "test_dataset = BertDataSet(new_test['clean'], None, tokenizer, 128, if_train = False)\n",
    "test_dataloader = dataloader.DataLoader(test_dataset, batch_size = 64, pin_memory = True, num_workers = 0, shuffle = True)\n",
    "\n",
    "config_path = './fintune_bert/config.json'\n",
    "model_path = './fintune_bert/model.safetensors'\n",
    "#new_model_path = './best_model.pth'\n",
    "\n",
    "config = transformers.BertConfig.from_json_file(config_path)\n",
    "best_model = transformers.BertForSequenceClassification.from_pretrained(model_path, config=config).to(device)\n",
    "\n",
    "#best_model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 6).to(device)\n",
    "\n",
    "probability_tensors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63978\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:28<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0479, 0.0182, 0.0309, 0.0180, 0.0261, 0.0176],\n",
      "        [0.0352, 0.0201, 0.0269, 0.0213, 0.0247, 0.0204],\n",
      "        [0.0352, 0.0201, 0.0270, 0.0216, 0.0258, 0.0210],\n",
      "        ...,\n",
      "        [0.0374, 0.0194, 0.0272, 0.0214, 0.0251, 0.0205],\n",
      "        [0.0388, 0.0196, 0.0264, 0.0210, 0.0265, 0.0200],\n",
      "        [0.0365, 0.0200, 0.0274, 0.0213, 0.0253, 0.0205]])\n"
     ]
    }
   ],
   "source": [
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    for test in tqdm(test_dataloader):\n",
    "        \n",
    "        ids = test['input_ids'].to(device)\n",
    "        mask = test['mask'].to(device)\n",
    "        outputs = best_model(ids, mask)\n",
    "        #print(outputs.keys())\n",
    "        results = outputs['logits']\n",
    "        #print(results)\n",
    "        \n",
    "        raw_predictions = torch.sigmoid(results)    \n",
    "        prediction = torch.where(raw_predictions > 0.5, 1, 0)\n",
    "        \n",
    "        #print(raw_predictions)\n",
    "        #print(prediction)\n",
    "        \n",
    "        if probability_tensors == None:\n",
    "            probability_tensors = raw_predictions\n",
    "        else:\n",
    "            probability_tensors = torch.cat((probability_tensors, raw_predictions), dim=0)\n",
    "            \n",
    "        #break\n",
    "        \n",
    "    probability_tensors = probability_tensors.detach().to('cpu')   \n",
    "    print(probability_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ground_truth = torch.tensor(new_test[['toxic', 'severe_toxic','obscene', 'threat', 'insult','identity_hate']].values)\n",
    "y_rand = torch.rand(200,6)\n",
    "# print(y_test)\n",
    "# print(y_label)\n",
    "get_roc_auc(ground_truth, probability_tensors)\n",
    "#get_roc_auc(y_label, y_rand)\n",
    "'''\n",
    "df = pd.DataFrame(probability_tensors)\n",
    "df.to_csv('test_dataset_output_predictions.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score : 0.5712584930723932\n",
      "Accuracy : 0.9622318088509592\n"
     ]
    }
   ],
   "source": [
    "probability = np.asarray(probability_tensors).flatten()\n",
    "ground_truth = new_test[['toxic', 'severe_toxic','obscene', 'threat', 'insult','identity_hate']].to_numpy().flatten()\n",
    "fpr, tpr, _ = roc_curve(ground_truth, probability)\n",
    "\n",
    "post_probability = np.where(probability > 0.5, 1, 0)\n",
    "accuracy = np.sum(ground_truth == post_probability)/probability.shape[0]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr)\n",
    "ax.set_title('ROC Curv')\n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "plt.show()\n",
    "\n",
    "print(\"AUC score : \" + str(roc_auc_score(ground_truth, probability)))\n",
    "print(\"Accuracy : \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9622318088509592"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = torch.tensor(new_test[['toxic', 'severe_toxic','obscene', 'threat', 'insult','identity_hate']].values)\n",
    "get_accuracy(ground_truth, probability_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7733908531057552"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_new_accuracy(ground_truth, probability_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_F1(ground_truth,probability_tensors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
